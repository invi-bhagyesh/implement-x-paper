# Paper Implementation

> Will try to implement as many paper as i can

## Structure

- **Autoencoders/**: Implementations of Encoder-Decoder model
- **DeepSeekV3/**: DeepSeek model replications and experiments.
- **DPO/**: Direct Preference Optimization and related RLHF methods.
- **Fine Tuning using PEFT/**: Parameter-Efficient Fine-Tuning methods.
- **Gemma3/**: Replications of Gemma model.
- **GPT/**: Generative Pretrained Transformer models.
- **LoRA/**: Low-Rank Adaptation for efficient fine-tuning.
- **ORPO/**: Online RLHF Preference Optimization.
- **VAE/**: Variational Autoencoders.
- ViT/: Vision Transformers

## Usage

Each folder is self-contained and includes code, scripts, and sometimes notebooks for replicating the results of the corresponding paper. Please refer to the README or notes within each subfolder for specific instructions.
